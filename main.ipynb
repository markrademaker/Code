{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install moviepy\n",
    "#!pip install transformers torchaudio\n",
    "#!pip install spleeter\n",
    "#!pip install torchaudio\n",
    "import media_embedder\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Don't Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "chunk:  65%|██████▍   | 36727/56726 [01:59<00:20, 966.20it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video loaded successfully: /Users/markrademaker/Downloads/Work/Scriptie/Data/Survivor_0-100.mov\n",
      "MoviePy - Writing audio in /Users/markrademaker/Downloads/Work/Scriptie/Data/Survivor_0-100_audio.mp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "chunk:  65%|██████▍   | 36727/56726 [02:02<00:20, 966.20it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "Audio extracted: /Users/markrademaker/Downloads/Work/Scriptie/Data/Survivor_0-100_audio.mp3\n",
      "Moviepy - Building video /Users/markrademaker/Downloads/Work/Scriptie/Data/Survivor_0-100_no_audio.mp4.\n",
      "Moviepy - Writing video /Users/markrademaker/Downloads/Work/Scriptie/Data/Survivor_0-100_no_audio.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "chunk:  65%|██████▍   | 36727/56726 [02:33<00:20, 966.20it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready /Users/markrademaker/Downloads/Work/Scriptie/Data/Survivor_0-100_no_audio.mp4\n",
      "Video without audio created: /Users/markrademaker/Downloads/Work/Scriptie/Data/Survivor_0-100_no_audio.mp4\n"
     ]
    }
   ],
   "source": [
    "from video_loader import VideoLoader\n",
    "#video_loader = VideoLoader(\"/Users/markrademaker/Downloads/Work/Scriptie/Data/Survivor_full.mov\")\n",
    "#video_loader.load_video()\n",
    "\n",
    "#video_loader.extract_subpart(0,100,\"/Users/markrademaker/Downloads/Work/Scriptie/Data/Survivor_0-100.mov\")\n",
    "sub_video_loader=VideoLoader(\"/Users/markrademaker/Downloads/Work/Scriptie/Data/Survivor_0-100.mov\")\n",
    "sub_video_loader.load_video()\n",
    "sub_video_loader.split_audio_video()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'separate_audio_sources' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/markrademaker/Downloads/Work/Scriptie/Code/main.ipynb Cell 4\u001b[0m line \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/markrademaker/Downloads/Work/Scriptie/Code/main.ipynb#W4sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m separate_audio_sources(\u001b[39m'\u001b[39m\u001b[39m/Users/markrademaker/Downloads/Work/Scriptie/Data/Survivor_full_audio.mp3\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39m/Users/markrademaker/Downloads/Work/Scriptie/Data/Survivor_full_audio_source.mp3\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'separate_audio_sources' is not defined"
     ]
    }
   ],
   "source": [
    "separate_audio_sources('/Users/markrademaker/Downloads/Work/Scriptie/Data/Survivor_full_audio.mp3', '/Users/markrademaker/Downloads/Work/Scriptie/Data/Survivor_full_audio_source.mp3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: av in /usr/local/anaconda3/lib/python3.9/site-packages (11.0.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install av"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN and Wav2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The video's frame rate is: 25.0 FPS\n",
      "Ignored unknown kwarg option normalize\n",
      "Ignored unknown kwarg option normalize\n",
      "Ignored unknown kwarg option normalize\n",
      "Ignored unknown kwarg option normalize\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base-960h and are newly initialized: ['wav2vec2.masked_spec_embed', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "PyAV is not installed, and is necessary for the video operations in torchvision.\nSee https://github.com/mikeboers/PyAV#installation for instructions on how to\ninstall PyAV on your system.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m/Users/markrademaker/Downloads/Work/Scriptie/Code/main.ipynb Cell 8\u001b[0m line \u001b[0;36m<cell line: 20>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/markrademaker/Downloads/Work/Scriptie/Code/main.ipynb#W4sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m chunk_duration\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m \u001b[39m#seconds for synchronization\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/markrademaker/Downloads/Work/Scriptie/Code/main.ipynb#W4sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m audio_embeddings \u001b[39m=\u001b[39m media_embed\u001b[39m.\u001b[39membed_audio(\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/markrademaker/Downloads/Work/Scriptie/Code/main.ipynb#W4sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m/Users/markrademaker/Downloads/Work/Scriptie/Data/Survivor_0-100_audio.mp3\u001b[39m\u001b[39m\"\u001b[39m, chunk_duration)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/markrademaker/Downloads/Work/Scriptie/Code/main.ipynb#W4sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m video_embeddings \u001b[39m=\u001b[39m media_embed\u001b[39m.\u001b[39;49membed_video(\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/markrademaker/Downloads/Work/Scriptie/Code/main.ipynb#W4sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m     \u001b[39m\"\u001b[39;49m\u001b[39m/Users/markrademaker/Downloads/Work/Scriptie/Data/Survivor_0-100_no_audio.mp4\u001b[39;49m\u001b[39m\"\u001b[39;49m, chunk_duration, fps)\n",
      "File \u001b[0;32m~/Downloads/Work/Scriptie/Code/media_embedder.py:59\u001b[0m, in \u001b[0;36mMediaEmbedder.embed_video\u001b[0;34m(self, video_path, chunk_duration, fps)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39meval()  \u001b[39m# Set the model to evaluation mode\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \u001b[39m# Load and preprocess video\u001b[39;00m\n\u001b[0;32m---> 59\u001b[0m video, _, _ \u001b[39m=\u001b[39m read_video(video_path, start_pts\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m, end_pts\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m, pts_unit\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39msec\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m     61\u001b[0m \u001b[39m# Calculate the number of frames per chunk\u001b[39;00m\n\u001b[1;32m     62\u001b[0m chunk_frame_count \u001b[39m=\u001b[39m chunk_duration \u001b[39m*\u001b[39m fps\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torchvision/io/video.py:264\u001b[0m, in \u001b[0;36mread_video\u001b[0;34m(filename, start_pts, end_pts, pts_unit)\u001b[0m\n\u001b[1;32m    261\u001b[0m \u001b[39mif\u001b[39;00m get_video_backend() \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mpyav\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    262\u001b[0m     \u001b[39mreturn\u001b[39;00m _video_opt\u001b[39m.\u001b[39m_read_video(filename, start_pts, end_pts, pts_unit)\n\u001b[0;32m--> 264\u001b[0m _check_av_available()\n\u001b[1;32m    266\u001b[0m \u001b[39mif\u001b[39;00m end_pts \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    267\u001b[0m     end_pts \u001b[39m=\u001b[39m \u001b[39mfloat\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39minf\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torchvision/io/video.py:39\u001b[0m, in \u001b[0;36m_check_av_available\u001b[0;34m()\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_check_av_available\u001b[39m() \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     38\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(av, \u001b[39mException\u001b[39;00m):\n\u001b[0;32m---> 39\u001b[0m         \u001b[39mraise\u001b[39;00m av\n",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "\u001b[1;32m/Users/markrademaker/Downloads/Work/Scriptie/Code/main.ipynb Cell 8\u001b[0m line \u001b[0;36m<cell line: 20>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/markrademaker/Downloads/Work/Scriptie/Code/main.ipynb#W4sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m chunk_duration\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m \u001b[39m#seconds for synchronization\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/markrademaker/Downloads/Work/Scriptie/Code/main.ipynb#W4sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m audio_embeddings \u001b[39m=\u001b[39m media_embed\u001b[39m.\u001b[39membed_audio(\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/markrademaker/Downloads/Work/Scriptie/Code/main.ipynb#W4sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m/Users/markrademaker/Downloads/Work/Scriptie/Data/Survivor_0-100_audio.mp3\u001b[39m\u001b[39m\"\u001b[39m, chunk_duration)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/markrademaker/Downloads/Work/Scriptie/Code/main.ipynb#W4sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m video_embeddings \u001b[39m=\u001b[39m media_embed\u001b[39m.\u001b[39;49membed_video(\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/markrademaker/Downloads/Work/Scriptie/Code/main.ipynb#W4sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m     \u001b[39m\"\u001b[39;49m\u001b[39m/Users/markrademaker/Downloads/Work/Scriptie/Data/Survivor_0-100_no_audio.mp4\u001b[39;49m\u001b[39m\"\u001b[39;49m, chunk_duration, fps)\n",
      "File \u001b[0;32m~/Downloads/Work/Scriptie/Code/media_embedder.py:59\u001b[0m, in \u001b[0;36mMediaEmbedder.embed_video\u001b[0;34m(self, video_path, chunk_duration, fps)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39meval()  \u001b[39m# Set the model to evaluation mode\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \u001b[39m# Load and preprocess video\u001b[39;00m\n\u001b[0;32m---> 59\u001b[0m video, _, _ \u001b[39m=\u001b[39m read_video(video_path, start_pts\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m, end_pts\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m, pts_unit\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39msec\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m     61\u001b[0m \u001b[39m# Calculate the number of frames per chunk\u001b[39;00m\n\u001b[1;32m     62\u001b[0m chunk_frame_count \u001b[39m=\u001b[39m chunk_duration \u001b[39m*\u001b[39m fps\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torchvision/io/video.py:264\u001b[0m, in \u001b[0;36mread_video\u001b[0;34m(filename, start_pts, end_pts, pts_unit)\u001b[0m\n\u001b[1;32m    261\u001b[0m \u001b[39mif\u001b[39;00m get_video_backend() \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mpyav\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    262\u001b[0m     \u001b[39mreturn\u001b[39;00m _video_opt\u001b[39m.\u001b[39m_read_video(filename, start_pts, end_pts, pts_unit)\n\u001b[0;32m--> 264\u001b[0m _check_av_available()\n\u001b[1;32m    266\u001b[0m \u001b[39mif\u001b[39;00m end_pts \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    267\u001b[0m     end_pts \u001b[39m=\u001b[39m \u001b[39mfloat\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39minf\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torchvision/io/video.py:39\u001b[0m, in \u001b[0;36m_check_av_available\u001b[0;34m()\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_check_av_available\u001b[39m() \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     38\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(av, \u001b[39mException\u001b[39;00m):\n\u001b[0;32m---> 39\u001b[0m         \u001b[39mraise\u001b[39;00m av\n",
      "\u001b[0;31mImportError\u001b[0m: PyAV is not installed, and is necessary for the video operations in torchvision.\nSee https://github.com/mikeboers/PyAV#installation for instructions on how to\ninstall PyAV on your system.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchaudio\n",
    "import torchaudio.transforms as T\n",
    "import media_embedder\n",
    "import cv2\n",
    "import media_embedder\n",
    "from media_embedder import MediaEmbedder\n",
    "video_path = \"/Users/markrademaker/Downloads/Work/Scriptie/Data/Survivor_0-100_no_audio.mp4\"\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "print(f\"The video's frame rate is: {fps} FPS\")\n",
    "\n",
    "cap.release()\n",
    "\n",
    "media_embed = MediaEmbedder()\n",
    "chunk_duration=1 #seconds for synchronization\n",
    "audio_embeddings = media_embed.embed_audio(\n",
    "    \"/Users/markrademaker/Downloads/Work/Scriptie/Data/Survivor_0-100_audio.mp3\", chunk_duration)\n",
    "video_embeddings = media_embed.embed_video(\n",
    "    \"/Users/markrademaker/Downloads/Work/Scriptie/Data/Survivor_0-100_no_audio.mp4\", chunk_duration, fps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## YAMnet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "yamnet = YAMnetClassifier()\n",
    "audio_data = your_audio_data_here  # This should be a waveform array\n",
    "yamnet_predictions = yamnet.predict(audio_data)\n",
    "yamnet_class_input = yamnet.process(audio_data)\n",
    "yamnet_embedding = yamnet.get_embedding(audio_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg16_classifier = VGG16Classifier()\n",
    "img_path = 'path_to_your_image.jpg'\n",
    "vgg_features = vgg16_classifier.get_features_before_last_layer(img_path)\n",
    "vgg_predictions = vgg16_classifier.predict(img_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recurrent Cells\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming labels and embeddings are defined\n",
    "scene_labels = [0,1]  # Replace with your scene labels\n",
    "# Create a combined dataset and data loader\n",
    "class CombinedDataset(Dataset):\n",
    "    def __init__(self, audio_embeddings, video_embeddings, labels):\n",
    "        self.audio_embeddings = audio_embeddings\n",
    "        self.video_embeddings = video_embeddings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.audio_embeddings[idx], self.video_embeddings[idx], self.labels[idx]\n",
    "\n",
    "combined_dataset = CombinedDataset(audio_embeddings, video_embeddings, scene_labels)\n",
    "combined_loader = DataLoader(combined_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "# Create an IntegratedModelTrainer instance\n",
    "trainer = IntegratedModelTrainer(audio_model, video_model, mlp_model, combined_loader)\n",
    "\n",
    "# Train the integrated model\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Later, for fine-tuning only the MLP\n",
    "trainer.toggle_biGRU_trainability(trainable=False)\n",
    "trainer.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
